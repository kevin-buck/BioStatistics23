print(above_threshold.vals)
above_threshold_table <- data.frame(year=yr.list, value=above_threshold.vals)
above_threshold_table <- data.frame(year=yr.list, value=above_threshold.vals)
write.csv(above_threshold_table,"/Users/kevinbuck/School/Research/VPD_Change/above_threshold_sb.csv", row.names = FALSE)
grids_av <- readRDS("~/Desktop/grids_av.Rda")
grids_av
grids_av <- readRDS("~/Desktop/grids_av_time_series.Rda")
grids_av_time_series
grids_av
grids_av_time_series <- readRDS("~/Desktop/grids_av_time_series.Rda")
grids_av <- readRDS("~/Desktop/grids_av.Rda")
grids_av_time_series
for(i in 1:1000){print i}
for(i in 1:1000){print(i)}
for(i in 1:1000){i+1}
for(i in 1:1000){print(i+1)}
growcheck <- function(yourvpd,threshold){yourvpd <= threshold}
View(growcheck)
list= rep(0,30)
for (i in 1:30){list[i]=2**1}
for (i in 1:30){list[i]=2**i}
c("first term",list)
long.index=1
assign(paste("above_4_Long_",long.index,sep=""), rep(NA,length(yr.list)))
yr.list=rep(0,40)
assign(paste("above_4_Long_",long.index,sep=""), rep(NA,length(yr.list)))
#this file will take the bare bones of the South Bend file to apply analysis
#to a larger spatial scale
#open ncdf library, retrieve file
#install.packages("ncdf4.helpers")
#install.packages("ncdf4",lib= "~/myRlibs",repos='https://cran.us.r-project.org')
require(ncdf4)
library(ncdf4)
#library(parallel)
# require(ggplot2)
# library(ggplot2)
file1 <- '/Users/kevinbuck/School/Research/VPD_Change/Datasets/1980to1983_sb.nc'
file2 <- '/Users/kevinbuck/School/Research/VPD_Change/Datasets/1984to1987_sb.nc'
file3 <- '/Users/kevinbuck/School/Research/VPD_Change/Datasets/1988to1991_sb.nc'
file4 <- '/Users/kevinbuck/School/Research/VPD_Change/Datasets/1992to1995_sb.nc'
file5 <- '/Users/kevinbuck/School/Research/VPD_Change/Datasets/1996to1999_sb.nc'
file6 <- '/Users/kevinbuck/School/Research/VPD_Change/Datasets/2000to2001_sb.nc'
file7 <- '/Users/kevinbuck/School/Research/VPD_Change/Datasets/2002to2005_sb.nc'
file8 <- '/Users/kevinbuck/School/Research/VPD_Change/Datasets/2006to2009_sb.nc'
file9 <- '/Users/kevinbuck/School/Research/VPD_Change/Datasets/2010to2013_sb.nc'
file10 <- '/Users/kevinbuck/School/Research/VPD_Change/Datasets/2014to2017_sb.nc'
file11 <- '/Users/kevinbuck/School/Research/VPD_Change/Datasets/2018to2021_sb.nc'
lat.index= placeholder
#this file will take the bare bones of the South Bend file to apply analysis
#to a larger spatial scale
#open ncdf library, retrieve file
#install.packages("ncdf4.helpers")
#install.packages("ncdf4",lib= "~/myRlibs",repos='https://cran.us.r-project.org')
require(ncdf4)
library(ncdf4)
#library(parallel)
# require(ggplot2)
# library(ggplot2)
file1 <- '/Users/kevinbuck/School/Research/VPD_Change/Datasets/1980to1983_sb.nc'
file2 <- '/Users/kevinbuck/School/Research/VPD_Change/Datasets/1984to1987_sb.nc'
file3 <- '/Users/kevinbuck/School/Research/VPD_Change/Datasets/1988to1991_sb.nc'
file4 <- '/Users/kevinbuck/School/Research/VPD_Change/Datasets/1992to1995_sb.nc'
file5 <- '/Users/kevinbuck/School/Research/VPD_Change/Datasets/1996to1999_sb.nc'
file6 <- '/Users/kevinbuck/School/Research/VPD_Change/Datasets/2000to2001_sb.nc'
file7 <- '/Users/kevinbuck/School/Research/VPD_Change/Datasets/2002to2005_sb.nc'
file8 <- '/Users/kevinbuck/School/Research/VPD_Change/Datasets/2006to2009_sb.nc'
file9 <- '/Users/kevinbuck/School/Research/VPD_Change/Datasets/2010to2013_sb.nc'
file10 <- '/Users/kevinbuck/School/Research/VPD_Change/Datasets/2014to2017_sb.nc'
file11 <- '/Users/kevinbuck/School/Research/VPD_Change/Datasets/2018to2021_sb.nc'
lat.index= 1
#long.index =1
file_count <- 11
file.vals <- seq(1,file_count)
#num_cores <- detectCores()
#options(cores = 8)
#getOption('cores')
Data1 <-  nc_open(file1, verbose=FALSE, return_on_error=TRUE)
Data2 <-  nc_open(file2, verbose=FALSE, return_on_error=TRUE)
Data3 <-  nc_open(file3, verbose=FALSE, return_on_error=TRUE)
Data4 <-  nc_open(file4, verbose=FALSE, return_on_error=TRUE)
Data5 <-  nc_open(file5, verbose=FALSE, return_on_error=TRUE)
Data6 <-  nc_open(file6, verbose=FALSE, return_on_error=TRUE)
Data7 <-  nc_open(file7, verbose=FALSE, return_on_error=TRUE)
Data8 <-  nc_open(file8, verbose=FALSE, return_on_error=TRUE)
Data9 <-  nc_open(file9, verbose=FALSE, return_on_error=TRUE)
Data10 <-  nc_open(file10, verbose=FALSE, return_on_error=TRUE)
Data11 <-  nc_open(file11, verbose=FALSE, return_on_error=TRUE)
#print(Data)
#dim(Data)
#Some basic time setup functions
getyear <- function(timedate){
as.integer(format(as.POSIXct(timedate*3600, origin="1900-01-01"),format="%Y"))}
getday <- function(timedate){
as.integer(format(as.POSIXct(timedate*3600, origin="1900-01-01"),format="%D"))}
gethour <- function(timedate){
as.integer(format(as.POSIXct(timedate*3600, origin="1900-01-01"),format="%H"))}
getdayofyr <- function(timedate){
as.integer(format(as.POSIXct(timedate*3600, origin="1900-01-01"),format="%j"))}
gethourofyr <- function(timedate){as.integer(gethour(timedate) + 1 + 24*(getdayofyr(timedate)-1))}
# defining day length calculation function \Inputs are:latitude in degrees (-90 to 90)
## and day of year
calc.daylength <- function(lat,doy){
pio180 <- pi/180.
day.angle <- 2 * pi * (doy-1)/365.0
solar.declination <- 0.006918 - 0.399912 * cos(day.angle) +
0.070257 * sin(day.angle) - 0.006758*cos(2.0*day.angle) +
0.000907 * sin(2.0*day.angle) - 0.002697 *
cos(3.0*day.angle) +
0.001480 * sin(3.0*day.angle)
acosarg <- -tan(lat*pio180)*tan(solar.declination)
if(acosarg < -1.0){acosarg = -1.0}
if(acosarg > 1.){acosarg = 1.0}
daylength <- 24./pi * acos(acosarg)*3600
return(daylength)
}
time_list <- readRDS("time_list.Rda")
#this file will take the bare bones of the South Bend file to apply analysis
#to a larger spatial scale
#open ncdf library, retrieve file
#install.packages("ncdf4.helpers")
#install.packages("ncdf4",lib= "~/myRlibs",repos='https://cran.us.r-project.org')
require(ncdf4)
library(ncdf4)
#library(parallel)
# require(ggplot2)
# library(ggplot2)
file1 <- '/Users/kevinbuck/School/Research/VPD_Change/Datasets/1980to1983_sb.nc'
file2 <- '/Users/kevinbuck/School/Research/VPD_Change/Datasets/1984to1987_sb.nc'
file3 <- '/Users/kevinbuck/School/Research/VPD_Change/Datasets/1988to1991_sb.nc'
file4 <- '/Users/kevinbuck/School/Research/VPD_Change/Datasets/1992to1995_sb.nc'
file5 <- '/Users/kevinbuck/School/Research/VPD_Change/Datasets/1996to1999_sb.nc'
file6 <- '/Users/kevinbuck/School/Research/VPD_Change/Datasets/2000to2001_sb.nc'
file7 <- '/Users/kevinbuck/School/Research/VPD_Change/Datasets/2002to2005_sb.nc'
file8 <- '/Users/kevinbuck/School/Research/VPD_Change/Datasets/2006to2009_sb.nc'
file9 <- '/Users/kevinbuck/School/Research/VPD_Change/Datasets/2010to2013_sb.nc'
file10 <- '/Users/kevinbuck/School/Research/VPD_Change/Datasets/2014to2017_sb.nc'
file11 <- '/Users/kevinbuck/School/Research/VPD_Change/Datasets/2018to2021_sb.nc'
lat.index= 1
#long.index =1
file_count <- 11
file.vals <- seq(1,file_count)
#num_cores <- detectCores()
#options(cores = 8)
#getOption('cores')
Data1 <-  nc_open(file1, verbose=FALSE, return_on_error=TRUE)
Data2 <-  nc_open(file2, verbose=FALSE, return_on_error=TRUE)
Data3 <-  nc_open(file3, verbose=FALSE, return_on_error=TRUE)
Data4 <-  nc_open(file4, verbose=FALSE, return_on_error=TRUE)
Data5 <-  nc_open(file5, verbose=FALSE, return_on_error=TRUE)
Data6 <-  nc_open(file6, verbose=FALSE, return_on_error=TRUE)
Data7 <-  nc_open(file7, verbose=FALSE, return_on_error=TRUE)
Data8 <-  nc_open(file8, verbose=FALSE, return_on_error=TRUE)
Data9 <-  nc_open(file9, verbose=FALSE, return_on_error=TRUE)
Data10 <-  nc_open(file10, verbose=FALSE, return_on_error=TRUE)
Data11 <-  nc_open(file11, verbose=FALSE, return_on_error=TRUE)
#print(Data)
#dim(Data)
#Some basic time setup functions
getyear <- function(timedate){
as.integer(format(as.POSIXct(timedate*3600, origin="1900-01-01"),format="%Y"))}
getday <- function(timedate){
as.integer(format(as.POSIXct(timedate*3600, origin="1900-01-01"),format="%D"))}
gethour <- function(timedate){
as.integer(format(as.POSIXct(timedate*3600, origin="1900-01-01"),format="%H"))}
getdayofyr <- function(timedate){
as.integer(format(as.POSIXct(timedate*3600, origin="1900-01-01"),format="%j"))}
gethourofyr <- function(timedate){as.integer(gethour(timedate) + 1 + 24*(getdayofyr(timedate)-1))}
# defining day length calculation function \Inputs are:latitude in degrees (-90 to 90)
## and day of year
calc.daylength <- function(lat,doy){
pio180 <- pi/180.
day.angle <- 2 * pi * (doy-1)/365.0
solar.declination <- 0.006918 - 0.399912 * cos(day.angle) +
0.070257 * sin(day.angle) - 0.006758*cos(2.0*day.angle) +
0.000907 * sin(2.0*day.angle) - 0.002697 *
cos(3.0*day.angle) +
0.001480 * sin(3.0*day.angle)
acosarg <- -tan(lat*pio180)*tan(solar.declination)
if(acosarg < -1.0){acosarg = -1.0}
if(acosarg > 1.){acosarg = 1.0}
daylength <- 24./pi * acos(acosarg)*3600
return(daylength)
}
time_list <- readRDS("/Users/kevinbuck/School/Research/VPD_Change/time_list.Rda")
long_list <- ncvar_get(Data11,"longitude")
lat_list <-  ncvar_get(Data11, "latitude")
lat.qty <- length(lat_list)
long.qty <- length(long_list)
#adjust for number of observations in file
obs <- length(time_list)
#calculations of the hour, julian day, year attributes of the time series
#also calculating number of years in the file
yr.list <- readRDS("/Users/kevinbuck/School/Research/VPD_Change/yr_list.Rda")
yr.qty <- length(yr.list)
yr.vals <- readRDS("/Users/kevinbuck/School/Research/VPD_Change/yr_vals.Rda")
doy.vals <- readRDS("/Users/kevinbuck/School/Research/VPD_Change/doy_vals.Rda")
hoy.vals <- readRDS("/Users/kevinbuck/School/Research/VPD_Change/hoy_vals.Rda")
yr.index <- function(obs_num){strtoi(match(yr.vals[obs_num],yr.list))
}
day_len.vals <- rep(0,obs)
for(i in 1:obs){
day_len.vals[i] <- calc.daylength(lat_list[lat.index],doy.vals[i])
}
###Functions
vp = function(tempc,presshpa){(1.0007+(3.46e-6*presshpa)) *6.1121*exp((17.502*tempc)/(240.97+tempc))}
#creating function for vpd
vpd <- function(dewtempc,tempc,presshpa){
abs(vp(dewtempc,presshpa) - vp(tempc,presshpa) )
}
growcheck <- function(yourvpd,threshold){yourvpd <= threshold}
##making matrix to store time series data
TS_Matrix <- matrix(nrow=(length(long_list)), ncol=length(yr.list),
dimnames = list(long_list,yr.list))
for (long.index in 1:long.qty){
#temporary list of dewpoints
dewpoint1 <- ncvar_get(Data1, "d2m",start = (c(long.index,lat.index,1)), count=(c(1,1,-1)))
dewpoint2 <- ncvar_get(Data2, "d2m",start = (c(long.index,lat.index,1)), count=(c(1,1,-1)))
dewpoint3 <- ncvar_get(Data3, "d2m",start = (c(long.index,lat.index,1)), count=(c(1,1,-1)))
dewpoint4 <- ncvar_get(Data4, "d2m",start = (c(long.index,lat.index,1)), count=(c(1,1,-1)))
dewpoint5 <- ncvar_get(Data5, "d2m",start = (c(long.index,lat.index,1)), count=(c(1,1,-1)))
dewpoint6 <- ncvar_get(Data6, "d2m",start = (c(long.index,lat.index,1)), count=(c(1,1,-1)))
dewpoint7 <- ncvar_get(Data7, "d2m",start = (c(long.index,lat.index,1)), count=(c(1,1,-1)))
dewpoint8 <- ncvar_get(Data8, "d2m",start = (c(long.index,lat.index,1)), count=(c(1,1,-1)))
dewpoint9 <- ncvar_get(Data9, "d2m",start = (c(long.index,lat.index,1)), count=(c(1,1,-1)))
dewpoint10 <- ncvar_get(Data10, "d2m",start = (c(long.index,lat.index,1)), count=(c(1,1,-1)))
dewpoint11 <- ncvar_get(Data11, "d2m",start = (c(long.index,lat.index,1)), count=(c(1,1,-1)))
dewpoint_list <- c(dewpoint1[6:35064],
dewpoint2[6:35064],
dewpoint3[6:35064],
dewpoint4[6:35064],
dewpoint5[6:35064],
dewpoint6[6:17544],
dewpoint7[6:35064],
dewpoint8[6:35064],
dewpoint9[6:35064],
dewpoint10[6:35064],
dewpoint11[6:35064])
#temporary list of temps
temp1 <- ncvar_get(Data1, "t2m",start = (c(long.index,lat.index,1)), count=(c(1,1,-1)))
temp2 <- ncvar_get(Data2, "t2m",start = (c(long.index,lat.index,1)), count=(c(1,1,-1)))
temp3 <- ncvar_get(Data3, "t2m",start = (c(long.index,lat.index,1)), count=(c(1,1,-1)))
temp4 <- ncvar_get(Data4, "t2m",start = (c(long.index,lat.index,1)), count=(c(1,1,-1)))
temp5 <- ncvar_get(Data5, "t2m",start = (c(long.index,lat.index,1)), count=(c(1,1,-1)))
temp6 <- ncvar_get(Data6, "t2m",start = (c(long.index,lat.index,1)), count=(c(1,1,-1)))
temp7 <- ncvar_get(Data7, "t2m",start = (c(long.index,lat.index,1)), count=(c(1,1,-1)))
temp8 <- ncvar_get(Data8, "t2m",start = (c(long.index,lat.index,1)), count=(c(1,1,-1)))
temp9 <- ncvar_get(Data9, "t2m",start = (c(long.index,lat.index,1)), count=(c(1,1,-1)))
temp10 <- ncvar_get(Data10, "t2m",start = (c(long.index,lat.index,1)), count=(c(1,1,-1)))
temp11 <- ncvar_get(Data11, "t2m",start = (c(long.index,lat.index,1)), count=(c(1,1,-1)))
temp_list <- c(temp1[6:35064],
temp2[6:35064],
temp3[6:35064],
temp4[6:35064],
temp5[6:35064],
temp6[6:17544],
temp7[6:35064],
temp8[6:35064],
temp9[6:35064],
temp10[6:35064],
temp11[6:35064])
#temporary list of surfacepressures
sp1 <- ncvar_get(Data1, "sp",start = (c(long.index,lat.index,1)), count=(c(1,1,-1)))
sp2 <- ncvar_get(Data2, "sp",start = (c(long.index,lat.index,1)), count=(c(1,1,-1)))
sp3 <- ncvar_get(Data3, "sp",start = (c(long.index,lat.index,1)), count=(c(1,1,-1)))
sp4 <- ncvar_get(Data4, "sp",start = (c(long.index,lat.index,1)), count=(c(1,1,-1)))
sp5 <- ncvar_get(Data5, "sp",start = (c(long.index,lat.index,1)), count=(c(1,1,-1)))
sp6 <- ncvar_get(Data6, "sp",start = (c(long.index,lat.index,1)), count=(c(1,1,-1)))
sp7 <- ncvar_get(Data7, "sp",start = (c(long.index,lat.index,1)), count=(c(1,1,-1)))
sp8 <- ncvar_get(Data8, "sp",start = (c(long.index,lat.index,1)), count=(c(1,1,-1)))
sp9 <- ncvar_get(Data9, "sp",start = (c(long.index,lat.index,1)), count=(c(1,1,-1)))
sp10 <- ncvar_get(Data10, "sp",start = (c(long.index,lat.index,1)), count=(c(1,1,-1)))
sp11 <- ncvar_get(Data11, "sp",start = (c(long.index,lat.index,1)), count=(c(1,1,-1)))
surfpressure_list <- c(sp1[6:35064],
sp2[6:35064],
sp3[6:35064],
sp4[6:35064],
sp5[6:35064],
sp6[6:17544],
sp7[6:35064],
sp8[6:35064],
sp9[6:35064],
sp10[6:35064],
sp11[6:35064])
#making an array to store data and giving it column names
column_names <- c("Time", "Dew Pt Temp", "Temp", "VPD", "DayLength",
"DailyAvTemp", "DailyGDD", "GDDCumul")
vals <- array(data=0,dim=c(8784,8,yr.qty),
dimnames=list(seq(1,8784),column_names,yr.list))
### FILLING The Temp DATA ARRAY
##
#
for(i in 1:obs-1){
vals[hoy.vals[i],"Time",yr.index(i)] <- time_list[i]
vals[hoy.vals[i],"Dew Pt Temp",yr.index(i)] <- dewpoint_list[i]
vals[hoy.vals[i],"Temp",yr.index(i)] <- temp_list[i]
vals[hoy.vals[i],"VPD",yr.index(i)] <-vpd(dewpoint_list[i]-273.15,temp_list[i]-273.15,
surfpressure_list[i])
vals[hoy.vals[i],"DayLength",yr.index(i)] <- day_len.vals[i]
}
#Filling matrix w the daily GDD value for each day
dayav <- function(i){
mean(temp_list[i:(i+23)])
}
day.av.vals <- rep(0,obs)
for(i in 2:(obs-24)){
if(gethour(i) == 1){
day.av.vals[i] <- dayav(i)
}
else(day.av.vals[i] <- day.av.vals[i-1])
}
for (i in 1:obs){
vals[hoy.vals[i],"DailyAvTemp",yr.index(i)] <- day.av.vals[i]
}
for (i in 1:obs){
vals[hoy.vals[i],"DailyGDD",yr.index(i)] <-
max(0,(day.av.vals[i]-278.15))
}
#filling matrix with the cumulative GDD value for each day
gdd_cumul <- 0
for (i in 1:obs) {
if(hoy.vals[i] != 1 & gethour(i) == 1){
gdd_cumul = gdd_cumul + vals[hoy.vals[i-1],"DailyGDD",yr.index(i)]
vals[hoy.vals[i],"GDDCumul",yr.index(i)] = gdd_cumul
}
else if(hoy.vals[i] == 1){
gdd_cumul = 0
vals[1,"GDDCumul",yr.index(i)] = 0
}
else{
vals[hoy.vals[i],"GDDCumul",yr.index(i)] = gdd_cumul
}
}
#figuring out the first and last day of the growing season
first_growth.vals <- rep(0,yr.qty)
for (i in 1:yr.qty){
for (x in 1:8784){
if(vals[x,"GDDCumul",i] >=100 ) {
first_growth.vals[i] <- x
break
}
}
}
last_growth.vals <-rep(0,yr.qty)
for (i in 1:yr.qty){
for (x in 3500:8784){
if(vals[x,"DayLength",i] < 39300) {
last_growth.vals[i] <- x
break
}
}
}
#defining function returning a vector of the VPD for the growing season of a given year
growing_season_vpd <- function(year){
yeararg <- match(year,yr.list)
return(vals[first_growth.vals[yeararg]:last_growth.vals[yeararg],"VPD",yeararg])
}
#Storing Change of Percentage above 4hPa and linear regression fit
above_4 <-  rep(NA,length(yr.list))
for (year in yr.list){
above_4 <- (1-(sum(growcheck(growing_season_vpd(year),4))/
(length(growing_season_vpd(year)))))
}
TS_Matrix[lat.index,] = above_4
}
saveRDS(TS_Matrix,file=(paste("/Users/kevinbuck/School/Research/VPD_Change/Raw_TS_Lat_",
as.character(lat_list[lat.index]),".Rda",sep="")))
load("~/Desktop/Raw_TS_Lat_42.Rda")
load("/Users/kevinbuck/Desktop/Raw_TS_Lat_42.Rda")
TS <- readRDS("Users/kevinbuck/Desktop/Raw_TS_42.Rda")
TS <- readRDS("/Users/kevinbuck/Desktop/Raw_TS_42.Rda")
TS <- readRDS(file="/Users/kevinbuck/Desktop/Raw_TS_Lat_42.Rda")
View(TS)
yr.list <- readRDS("yr_list.Rda")
yr.list <- readRDS(file="/Users/kevinbuck/School/Research/VPD_Change/yr_list.Rda")
yr.list[1]
yr.list[2]
growcheck <- function(yourvpd,threshold){yourvpd <= threshold}
test_ts <- rand(n=40,m=4.55)
test_ts <- rnorm(n=40,m=4.55)
above_4 <-  rep(NA,length(yr.list))
for (year.index in 1:yr.qty){
above_4[yr.index] <- (1-(sum(growcheck(test_ts,4)))/
(length(test_ts)))
}
yr.qty=length(yr.list)
for (year.index in 1:yr.qty){
above_4[yr.index] <- (1-(sum(growcheck(test_ts,4)))/
(length(test_ts)))
}
test_ts <- rnorm(4000,mean=4.65, sd=1.2)
for (yr.index in 1:yr.qty){
above_4[yr.index] <- (1-(sum(growcheck(test_ts,4)))/
(length(test_ts)))
}
growcheck(test_ts,4)
sum(growcheck(test_ts,4))
1-(sum(growcheck(test_ts,4)))/length(test_ts)
test_ts <- rnorm(4000,mean=4.65, sd=1.2)
1-(sum(growcheck(test_ts,4)))/length(test_ts)
load("/Users/kevinbuck/Desktop/Raw_TS_Lat_45.Rda")
TS <- readRDS(file="/Users/kevinbuck/Desktop/Raw_TS_Lat_45.Rda")
TS
load("~/Desktop/Raw_TS_Lat_50.Rda")
test <- readRDS("~/Desktop/Raw_TS_Lat_50.Rda"")
test <- readRDS("~/Desktop/Raw_TS_Lat_50.Rda")
test
View(test)
test1<- readRDS(file'~/Desktop/Raw_TS_Lat_25.Rda')
test1<- readRDS(file='~/Desktop/Raw_TS_Lat_25.Rda')
test2<- readRDS(file='~/Desktop/Raw_TS_Lat_24.75.Rda')
test3<- readRDS(file='~/Desktop/Raw_TS_Lat_24.5.Rda')
test4<- readRDS(file='~/Desktop/Raw_TS_Lat_24.25.Rda')
test5<- readRDS(file='~/Desktop/Raw_TS_Lat_24.Rda')
View(test1)
View(test2)
View(test3)
View(test4)
View(test5)
test6 <- readRDS(file='~/Desktop/Raw_TS_Lat_28.5.Rda')
View(test6)
summary(test6)
summary(test)
summary(test2)
print("test")
setwd("~/Desktop/BioStats/")
pwd
getwd()
ls
getwd()
setwd("~/Desktop/Biostats/Week01")
setwd("~/Desktop/Biostats/Week0")
setwd("~/Desktop/Biostats/Week03")
getwd()
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Desktop/Biostats/Week03")
library(tidyverse) #importing tidyverse
gene <- read.csv(file="Gene.csv")
glimpse(gene) #peeking at the data
head(gene)
summary(gene)
hist(gene$size) #making a histogram of gene size
?hist()
hist(gene$size, breaks=10) #making a histogram of gene size
hist(gene$size, breaks=20) #making a histogram of gene size
?filter()
gene_sort <- gene %>%
filter(size < 15000)
hist(gene_sort)
gene_sort <- gene %>%
filter(size < 15000)
hist(gene_sort$size)
gene_sort <- gene %>%    #creating a new object from gene data piped into
filter(size < 15000) # the filter function to get only genes with l< 15000
#makng histogram of the gene length data
hist(gene_sort$size,xlab-"Gene Size (Nucleotides)")
gene_sort <- gene %>%    #creating a new object from gene data piped into
filter(size < 15000) # the filter function to get only genes with l< 15000
#makng histogram of the gene length data
hist(gene_sort$size,xlab="Gene Size (Nucleotides)")
gene_sort <- gene %>%    #creating a new object from gene data piped into
filter(size < 15000) # the filter function to get only genes with l< 15000
#makng histogram of the gene length data
hist(gene_sort$size,xlab="Gene Size (Nucleotides)",main="Gene Lengths")
gene_sort <- gene %>%    #creating a new object from gene data piped into
filter(size < 15000) # the filter function to get only genes with l< 15000
#makng histogram of the gene length data
hist(gene_sort$size,xlab="Gene Size (Nucleotides)",main="Gene Lengths", fill="navy")
gene_sort <- gene %>%    #creating a new object from gene data piped into
filter(size < 15000) # the filter function to get only genes with l< 15000
#makng histogram of the gene length data
hist(gene_sort$size,xlab="Gene Size (Nucleotides)",main="Gene Lengths", col="navy")
summarize(mean=mean(gene$size))
summarize(gene$size)
View(gene)
?summarize()
summarize(gene)
summarize(gene$size)
summarize(mean=mean(size))
summarize(data=gene,mean=mean(size))
summarize(.data=gene,mean=mean(size))
summarize(.data=gene,median(size))
summarize(.data=gene,mean=mean(size)) #calculating mean gene size
summarize(.data=gene,median(size)) #calculating median gene size
summarize(.data=gene,mean=mean(size)) #calculating mean gene size
summarize(.data=gene,median=median(size)) #calculating median gene size
gene_sort <- gene %>%
filter(size < 15000) %>%
summarize(mean=mean(size),median=median(size))
View(gene_sort)
#creating a new object from gene data piped into a filter function removing rows where size exceeds 15000 bp
gene_sort <- gene %>%
filter(size < 15000)
#makng histogram of the gene length data
hist(gene_sort$size,xlab="Gene Size (Nucleotides)",main="Gene Lengths", col="navy")
#creating new variable for stats w sorted data, sending gene data into start of pipe
gene_sorted_stats <- gene %>%
#filtering data to be only size < 15000
filter(size < 15000) %>%
#calculating mean and median of the filtered data to be stored
summarize(mean=mean(size),median=median(size))
View(gene_sorted_stats)
#creating new variable for stats w sorted data, sending gene data into start of pipe
gene_sorted_stats <- gene %>%
#filtering data to be only size < 15000
filter(size < 15000) %>%
#calculating mean and median of the filtered data to be stored
summarize(mean=mean(size),median=median(size))
print(gene_sorted_stats)
#calculating mean and median gene size from gene data
summarize(.data=gene,mean=mean(size),median=median(size))
3511.457-3407.496
2744-2727.5
